
ğŸš€ Starting training for language: dutch (nl)
ğŸ“‚ Loading JASMIN dataset...
ğŸ”€ Shuffling and splitting dataset...

ğŸ” Dataset stats:
â€¢ train: 2392 samples
{'audio': {'path': '/vol/bigdata3/datasets3/dutch_child_audio/jasmin/audio_segments/fn000065_1_022.wav', 'array': array([0., 0., 0., ..., 0., 0., 0.], shape=(38725,)), 'sampling_rate': 16000}, 'sentence': 'bloemen en de zon'}
â€¢ validation: 299 samples
{'audio': {'path': '/vol/bigdata3/datasets3/dutch_child_audio/jasmin/audio_segments/fn000105_1_038.wav', 'array': array([0., 0., 0., ..., 0., 0., 0.], shape=(30184,)), 'sampling_rate': 16000}, 'sentence': 'een mp drie speler'}
â€¢ test: 300 samples
{'audio': {'path': '/vol/bigdata3/datasets3/dutch_child_audio/jasmin/audio_segments/fn000554_1_005.wav', 'array': array([0., 0., 0., ..., 0., 0., 0.], shape=(17568,)), 'sampling_rate': 16000}, 'sentence': 'de auto'}

ğŸ§ª Features:
{'audio': Audio(sampling_rate=16000, mono=True, decode=True, id=None), 'sentence': Value(dtype='string', id=None)}
ğŸ§¹ Filtering...
ğŸ”„ Preprocessing...
ğŸ’» Device: cuda
ğŸ”¥ Training...
{'eval_loss': 0.2621346712112427, 'eval_runtime': 272.9068, 'eval_samples_per_second': 1.096, 'eval_steps_per_second': 1.096, 'epoch': 1.0}
{'loss': 0.923, 'grad_norm': 8.76977825164795, 'learning_rate': 3.905590062111801e-06, 'epoch': 1.67}
{'eval_loss': 0.22952055931091309, 'eval_runtime': 250.646, 'eval_samples_per_second': 1.193, 'eval_steps_per_second': 1.193, 'epoch': 2.0}
âœ“ Saving BEST model at epoch 3 with eval_loss 0.2295
{'eval_loss': 0.23821526765823364, 'eval_runtime': 266.138, 'eval_samples_per_second': 1.123, 'eval_steps_per_second': 1.123, 'epoch': 3.0}
{'loss': 0.0669, 'grad_norm': 1.8957273960113525, 'learning_rate': 3.8100334448160533e-06, 'epoch': 3.34}
{'eval_loss': 0.24470430612564087, 'eval_runtime': 242.468, 'eval_samples_per_second': 1.233, 'eval_steps_per_second': 1.233, 'epoch': 4.0}
{'eval_loss': 0.2576533555984497, 'eval_runtime': 252.7528, 'eval_samples_per_second': 1.183, 'eval_steps_per_second': 1.183, 'epoch': 5.0}
{'loss': 0.0149, 'grad_norm': 0.2623804211616516, 'learning_rate': 3.7144768275203057e-06, 'epoch': 5.02}
{'eval_loss': 0.27080389857292175, 'eval_runtime': 258.4532, 'eval_samples_per_second': 1.157, 'eval_steps_per_second': 1.157, 'epoch': 6.0}
{'loss': 0.0055, 'grad_norm': 0.15634720027446747, 'learning_rate': 3.6189202102245578e-06, 'epoch': 6.69}
{'eval_loss': 0.2585506737232208, 'eval_runtime': 250.9564, 'eval_samples_per_second': 1.191, 'eval_steps_per_second': 1.191, 'epoch': 7.0}
{'eval_loss': 0.26071202754974365, 'eval_runtime': 256.4663, 'eval_samples_per_second': 1.166, 'eval_steps_per_second': 1.166, 'epoch': 8.0}
{'loss': 0.0018, 'grad_norm': 0.04259448125958443, 'learning_rate': 3.5233635929288102e-06, 'epoch': 8.36}
{'eval_loss': 0.2692270874977112, 'eval_runtime': 269.4707, 'eval_samples_per_second': 1.11, 'eval_steps_per_second': 1.11, 'epoch': 9.0}
{'train_runtime': 20356.8856, 'train_samples_per_second': 8.225, 'train_steps_per_second': 1.028, 'train_loss': 0.18811677866977017, 'epoch': 9.0}
ğŸ’¾ Saving final model...
ğŸ“ˆ Final evaluation on test set...

=== Final Test Metrics ===
eval_loss: 0.2387
eval_runtime: 266.1349
eval_samples_per_second: 1.1270
eval_steps_per_second: 1.1270
epoch: 9.0000
